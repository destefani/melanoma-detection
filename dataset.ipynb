{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from monai.data import CacheDataset\n",
    "from monai.data.utils import partition_dataset_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "Process the image paths and labels into a easi to handle format to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data function\n",
    "def image_name(image_file):\n",
    "    'Extracts the image name from the image path'\n",
    "    return os.path.basename(image_file).split('.')[0]\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(images_dir, labels_df, format='.jpg', test_size=0.2, seed=42):\n",
    "\n",
    "    # images_dir = 'dataset/siim-isic-melanoma-classification/train'\n",
    "    # label_data = 'dataset/siim-isic-melanoma-classification/train.csv'\n",
    "\n",
    "    image_files = sorted(\n",
    "        glob.glob(os.path.join(images_dir, f'*{format}'))\n",
    "        \n",
    "    )\n",
    "\n",
    "    files_df = pd.read_csv(labels_df)\n",
    "\n",
    "    image_list  = files_df['image_name'].to_list()\n",
    "    labels_list = files_df['target'].to_list()\n",
    "    data_dict   = {k: v for k, v in zip(image_list, labels_list)}\n",
    "    \n",
    "\n",
    "    labels_list = [data_dict[image_name(i)] for i in image_files]\n",
    "\n",
    "    train, val =  partition_dataset_classes(\n",
    "        image_files, labels_list, ratios=[(1 - test_size), test_size], shuffle=True\n",
    "        )\n",
    "    train_dicts = [{'image': i, 'label': data_dict[image_name(i)]} for i in train]\n",
    "    val_dicts   = [{'image': i, 'label': data_dict[image_name(i)]} for i in val]\n",
    "\n",
    "    return train_dicts, val_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = prepare_data(\n",
    "    images_dir='dataset/siim-isic-melanoma-classification/jpeg/train',\n",
    "    labels_df='dataset/siim-isic-melanoma-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': 'dataset/siim-isic-melanoma-classification/jpeg/train/ISIC_0246090.jpg',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    AsChannelFirstd,\n",
    "    Compose,\n",
    "    CenterSpatialCropd,\n",
    "    LoadImaged,\n",
    "    EnsureTyped,\n",
    "    NormalizeIntensityd,\n",
    "    Resized,\n",
    "    ToTensord\n",
    ")\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [   \n",
    "        LoadImaged('image', image_only=True),\n",
    "        AsChannelFirstd('image'),\n",
    "        Resized('image', (256, 256)),\n",
    "        CenterSpatialCropd('image', 224),\n",
    "        NormalizeIntensityd('image'),\n",
    "        ToTensord('image')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 50/50 [00:05<00:00,  9.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, label_data = prepare_data(\n",
    "    images_dir='dataset/siim-isic-melanoma-classification/jpeg/train',\n",
    "    labels_df='dataset/siim-isic-melanoma-classification/train.csv')\n",
    "\n",
    "\n",
    "train_data = train_data[:500]\n",
    "label_data = label_data[:500]\n",
    "\n",
    "train_ds = CacheDataset(\n",
    "    data=train_data,\n",
    "    transform=train_transforms,\n",
    "    num_workers=8,\n",
    "    cache_rate=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd1032cfb14c559a18a67512f34292cc729016950064e3ec8b321ae3e541fadc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('melanoma': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
